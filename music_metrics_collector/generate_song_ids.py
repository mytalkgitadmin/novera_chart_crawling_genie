"""ê²€ìƒ‰ìš© CSV(search_data.csv)ë¥¼ ê¸°ë°˜ìœ¼ë¡œ song_idë¥¼ ì±„ìš°ëŠ” ë³´ì¡° ìŠ¤í¬ë¦½íŠ¸.

ì‚¬ìš© íë¦„:

1) í”Œë«í¼ë³„ ê²€ìƒ‰ í‚¤ì›Œë“œ CSV ì‘ì„±
   - ê²½ë¡œ: resource/{í”Œë«í¼ëª…}/search_data.csv
   - ì»¬ëŸ¼: song_name, artist_name, album_name, song_type, track_code, isrc
   ì˜ˆ:
       song_name,artist_name,album_name,song_type,track_code,isrc
       ê³¡ì œëª©1,ì•„í‹°ìŠ¤íŠ¸1,ì•¨ë²”ëª…1,ì¥ë¥´1,A1147227T001,KSB012324080
       ê³¡ì œëª©2,ì•„í‹°ìŠ¤íŠ¸2,ì•¨ë²”ëª…2,ì¥ë¥´2,A1147227T002,KSB012324081

2) ë³¸ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
   - ì˜ˆ: python -m music_metrics_collector.generate_song_ids --config config.yaml

3) ê° í”Œë«í¼ë³„ song_data.csv ìƒì„±/ê°±ì‹ 
   - ê²½ë¡œ: resource/{í”Œë«í¼ëª…}/song_data.csv
   - ì»¬ëŸ¼: song_id, track_code, isrc, song_type (song_typeì€ ë§¨ ë’¤)
"""

import argparse
import csv
import logging
import sys
from pathlib import Path
from typing import Dict, List, Optional

from bs4 import BeautifulSoup

from .fetcher import Fetcher
from .main import load_config


logger = logging.getLogger(__name__)


def _read_search_data(platform: str, resource_dir: str) -> List[Dict[str, str]]:
    """í”Œë«í¼ë³„ search_data.csvì—ì„œ ëª¨ë“  í•„ë“œë¥¼ ì½ì–´ì˜¨ë‹¤."""
    csv_path = Path(resource_dir) / platform / "search_data.csv"
    if not csv_path.exists():
        logger.warning(f"[{platform}] search_data.csvë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {csv_path}")
        return []

    rows: List[Dict[str, str]] = []
    try:
        # utf-8-sigë¥¼ ì‚¬ìš©í•˜ì—¬ BOM(Byte Order Mark)ì„ ìë™ìœ¼ë¡œ ì œê±°
        with open(csv_path, "r", encoding="utf-8-sig") as f:
            reader = csv.DictReader(f)
            # BOMì´ ë‚¨ì•„ìˆì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì»¬ëŸ¼ëª…ì—ì„œë„ ì œê±°
            reader.fieldnames = [name.strip('\ufeff') if name else name for name in (reader.fieldnames or [])]
            for row in reader:
                # BOMì´ í¬í•¨ëœ í‚¤ë„ ì²˜ë¦¬
                row_cleaned = {}
                for key, value in row.items():
                    cleaned_key = key.strip('\ufeff') if key else key
                    row_cleaned[cleaned_key] = value
                
                # ê²€ìƒ‰ì— í•„ìš”í•œ ê¸°ë³¸ í•„ë“œ
                song_name = (row_cleaned.get("song_name_kor") or "").strip()
                artist_name = (row_cleaned.get("artist_name_kor") or "").strip()
                
                if not song_name and not artist_name:
                    continue
                
                # ìƒˆë¡œìš´ ëª…ì„¸ì— ë§ì¶° ëª¨ë“  í•„ë“œ ì¶”ì¶œ (20ê°œ í•„ë“œ)
                rows.append({
                    # ê²€ìƒ‰ìš© í•„ë“œ
                    "song_name": song_name,
                    "artist_name": artist_name,
                    "album_name": (row_cleaned.get("album_name_kor") or "").strip(),
                    
                    # song_data.csv ì¶œë ¥ìš© 20ê°œ í•„ë“œ (ìˆœì„œëŒ€ë¡œ)
                    "platform_seq": (row_cleaned.get("platform_seq") or "").strip(),
                    "platform_name": (row_cleaned.get("platform_name") or "").strip(),
                    "song_type_txt": (row_cleaned.get("song_type_text") or "").strip(),
                    "album_cd": (row_cleaned.get("album_cd") or "").strip(),
                    "album_name_kor": (row_cleaned.get("album_name_kor") or "").strip(),
                    "album_name_eng": (row_cleaned.get("album_name_eng") or "").strip(),
                    "song_cd": (row_cleaned.get("song_cd") or "").strip(),
                    "song_name_kor": song_name,
                    "song_name_eng": (row_cleaned.get("song_name_eng") or "").strip(),
                    "song_release_date": (row_cleaned.get("song_release_date") or "").strip(),
                    "artist_cd": (row_cleaned.get("artist_cd") or "").strip(),
                    "artist_name_kor": artist_name,
                    "artist_name_eng": (row_cleaned.get("artist_name_eng") or "").strip(),
                    "mem_cd": (row_cleaned.get("mem_cd") or "").strip(),
                    "mem_name": (row_cleaned.get("mem_name") or "").strip(),
                    "track_cd": (row_cleaned.get("track_cd") or "").strip(),
                    "isrc_cd": (row_cleaned.get("isrc_cd") or "").strip(),
                    "interest_yn": (row_cleaned.get("interest_yn") or "n").strip(),
                })
    except Exception as e:
        logger.error(f"[{platform}] search_data.csv ì½ê¸° ì‹¤íŒ¨: {e}")
        return []

    logger.info(f"[{platform}] search_data.csvì—ì„œ {len(rows)}ê±´ì˜ ê²€ìƒ‰ í‚¤ì›Œë“œë¥¼ ì½ì—ˆìŠµë‹ˆë‹¤.")
    return rows


def _remove_japanese(text: str) -> str:
    """
    í…ìŠ¤íŠ¸ì—ì„œ ì¼ë³¸ì–´ ë¬¸ì(íˆë¼ê°€ë‚˜, ê°€íƒ€ì¹´ë‚˜, í•œì)ë¥¼ ì œê±°í•œë‹¤.
    ê´„í˜¸ë¡œ ê°ì‹¸ì§„ ì¼ë³¸ì–´ë„ í•¨ê»˜ ì œê±°í•œë‹¤.
    
    Args:
        text: ì²˜ë¦¬í•  í…ìŠ¤íŠ¸
    
    Returns:
        ì¼ë³¸ì–´ê°€ ì œê±°ëœ í…ìŠ¤íŠ¸
    """
    if not text:
        return ""
    
    import re
    # ì¼ë³¸ì–´ ë¬¸ì ë²”ìœ„: íˆë¼ê°€ë‚˜(ã-ã‚Ÿ), ê°€íƒ€ì¹´ë‚˜(ã‚¡-ãƒ¿), í•œì(ä¸€-é¾¯)
    # ê´„í˜¸ ì•ˆì— ì¼ë³¸ì–´ê°€ ìˆìœ¼ë©´ ê´„í˜¸ì§¸ ì œê±° (ì˜ˆ: "(ãƒ¦ãƒ³ãƒŠ)" â†’ "")
    text = re.sub(r'\([ã-ã‚Ÿã‚¡-ãƒ¿ä¸€-é¾¯]+\)', '', text)
    text = re.sub(r'\ï¼ˆ[ã-ã‚Ÿã‚¡-ãƒ¿ä¸€-é¾¯]+\ï¼‰', '', text)  # ì „ê° ê´„í˜¸
    # ë‚¨ì€ ì¼ë³¸ì–´ ë¬¸ì ì œê±°
    text = re.sub(r'[ã-ã‚Ÿã‚¡-ãƒ¿ä¸€-é¾¯]+', '', text)
    # ì—¬ëŸ¬ ê³µë°±ì„ í•˜ë‚˜ë¡œ ë³€í™˜
    text = " ".join(text.split())
    
    return text.strip()


def _preprocess_album_name(album_name: str) -> str:
    """
    ì•¨ë²”ëª…ì„ ê²€ìƒ‰ì— ì í•©í•˜ê²Œ ì „ì²˜ë¦¬í•œë‹¤.
    OST í‚¤ì›Œë“œ, Part ë²ˆí˜¸, ë²„ì „ ì •ë³´ ë“±ì„ ì œê±°í•œë‹¤.
    
    Args:
        album_name: ì›ë³¸ ì•¨ë²”ëª…
    
    Returns:
        ì „ì²˜ë¦¬ëœ ì•¨ë²”ëª…
    """
    if not album_name:
        return ""
    
    import re
    # ì¼ë³¸ì–´ ì œê±°
    album_name = _remove_japanese(album_name)
    
    # OST ê´€ë ¨ í‚¤ì›Œë“œ ì œê±°
    ost_patterns = [
        r'\s*\(Original Soundtrack\)',
        r'\s*\(Original Motion Picture Soundtrack\)',
        r'\s*\(Original Television Soundtrack\)',
        r'\s*Original Soundtrack',
        r'\s*Original Motion Picture Soundtrack',
        r'\s*Original Television Soundtrack',
        r'\s*OST',
        r'\s*O\.S\.T\.',
    ]
    for pattern in ost_patterns:
        album_name = re.sub(pattern, '', album_name, flags=re.IGNORECASE)
    
    # Part, Pt ë²ˆí˜¸ ì œê±° (ì˜ˆ: "Part.1", "Pt. 2", "Part 3")
    album_name = re.sub(r'\s*Pt\.?\s*\d+', '', album_name, flags=re.IGNORECASE)
    album_name = re.sub(r'\s*Part\.?\s*\d+', '', album_name, flags=re.IGNORECASE)
    
    # ë²„ì „ ì •ë³´ ì œê±° (ì˜ˆ: "2nd", "3rd", "Vol.1")
    album_name = re.sub(r'\s*\d+(st|nd|rd|th)', '', album_name, flags=re.IGNORECASE)
    album_name = re.sub(r'\s*Vol\.?\s*\d+', '', album_name, flags=re.IGNORECASE)
    
    # ì—¬ëŸ¬ ê³µë°±ì„ í•˜ë‚˜ë¡œ ë³€í™˜
    album_name = " ".join(album_name.split())
    
    return album_name.strip()


def _preprocess_artist_name(artist_name: str, aggressive: bool = False) -> str:
    """
    ì•„í‹°ìŠ¤íŠ¸ëª…ì„ ê²€ìƒ‰ì— ì í•©í•˜ê²Œ ì „ì²˜ë¦¬í•œë‹¤.
    feat., Feat. ì œê±° ë° ì½œë¼ë³´ ì•„í‹°ìŠ¤íŠ¸ ì²˜ë¦¬
    
    Args:
        artist_name: ì›ë³¸ ì•„í‹°ìŠ¤íŠ¸ëª…
        aggressive: Trueì¼ ê²½ìš° ê´„í˜¸ ì•ˆ ëª¨ë“  ë‚´ìš©ê³¼ ìˆ«ì ì œê±°
    
    Returns:
        ì „ì²˜ë¦¬ëœ ì•„í‹°ìŠ¤íŠ¸ëª…
    """
    if not artist_name:
        return ""
    
    import re
    # ì¼ë³¸ì–´ ì œê±°
    artist_name = _remove_japanese(artist_name)
    
    # feat., Feat. ì´í›„ ë¶€ë¶„ ì œê±° (ê´„í˜¸ ì•ˆ/ë°– ëª¨ë‘)
    artist_name = re.sub(r'\s*\(?\s*[Ff]eat\.?\s+[^\)]+\)?', '', artist_name)
    artist_name = re.sub(r'\s*\(?\s*[Ff]t\.?\s+[^\)]+\)?', '', artist_name)
    
    # ì½¤ë§ˆë¡œ êµ¬ë¶„ëœ ì½œë¼ë³´ ì•„í‹°ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ ì²« ë²ˆì§¸ë§Œ ì‚¬ìš©
    if ',' in artist_name:
        artist_name = artist_name.split(',')[0].strip()
    
    # aggressive ëª¨ë“œ: ê´„í˜¸ ì•ˆ ëª¨ë“  ë‚´ìš© ì œê±° ë° ìˆ«ì/ê¸°ìˆ˜ ì œê±°
    if aggressive:
        # ê´„í˜¸ ì•ˆ ë‚´ìš© ëª¨ë‘ ì œê±° ("ì •í‚¤ (ì •í¬ì›…)" â†’ "ì •í‚¤", "ë¯¼ë‹ˆ ((ì—¬ì)ì•„ì´ë“¤)" â†’ "ë¯¼ë‹ˆ")
        artist_name = re.sub(r'\s*\([^)]+\)', '', artist_name)
        artist_name = re.sub(r'\s*\ï¼ˆ[^ï¼‰]+\ï¼‰', '', artist_name)  # ì „ê° ê´„í˜¸
        
        # ìˆ«ì + "ê¸°" ì œê±° ("ë² ì´ë¹„ ë³µìŠ¤ 1ê¸°" â†’ "ë² ì´ë¹„ ë³µìŠ¤")
        artist_name = re.sub(r'\s*\d+ê¸°', '', artist_name)
        
        # ëì˜ ìˆ«ì ì œê±° ("ë² ì´ë¹„ ë³µìŠ¤ 1" â†’ "ë² ì´ë¹„ ë³µìŠ¤")
        artist_name = re.sub(r'\s+\d+$', '', artist_name)
    
    # ì—¬ëŸ¬ ê³µë°±ì„ í•˜ë‚˜ë¡œ ë³€í™˜
    artist_name = " ".join(artist_name.split())
    
    return artist_name.strip()


def _preprocess_song_name(song_name: str, aggressive: bool = False) -> str:
    """
    ê³¡ëª…ì„ ê²€ìƒ‰ì— ì í•©í•˜ê²Œ ì „ì²˜ë¦¬í•œë‹¤.
    
    Args:
        song_name: ì›ë³¸ ê³¡ëª…
        aggressive: Trueì¼ ê²½ìš° ê´„í˜¸ ì•ˆ ëª¨ë“  ë‚´ìš© ì œê±°
    
    Returns:
        ì „ì²˜ë¦¬ëœ ê³¡ëª…
    """
    if not song_name:
        return ""
    
    import re
    # ì¼ë³¸ì–´ ì œê±°
    song_name = _remove_japanese(song_name)
    
    # aggressive ëª¨ë“œ: ê´„í˜¸ ì•ˆ ëª¨ë“  ë‚´ìš© ì œê±°
    if aggressive:
        # ê´„í˜¸ ì•ˆ ë‚´ìš© ì œê±° ("ì²«ì‚¬ë‘(From ì‘ë‹µí•˜ë¼ 1994)" â†’ "ì²«ì‚¬ë‘")
        song_name = re.sub(r'\s*\([^)]+\)', '', song_name)
        song_name = re.sub(r'\s*\ï¼ˆ[^ï¼‰]+\ï¼‰', '', song_name)  # ì „ê° ê´„í˜¸
    
    # ì—¬ëŸ¬ ê³µë°±ì„ í•˜ë‚˜ë¡œ ë³€í™˜
    song_name = " ".join(song_name.split())
    
    return song_name.strip()


def _sanitize_search_text(text: str) -> str:
    """
    ê²€ìƒ‰ í…ìŠ¤íŠ¸ì—ì„œ íŠ¹ìˆ˜ë¬¸ìë¥¼ ì œê±°í•˜ê±°ë‚˜ ë³€í™˜í•œë‹¤.
    í”Œë«í¼ ê²€ìƒ‰ì—ì„œ ë¬¸ì œê°€ ë  ìˆ˜ ìˆëŠ” íŠ¹ìˆ˜ë¬¸ìë¥¼ ì²˜ë¦¬í•œë‹¤.
    """
    if not text:
        return ""
    
    # & ê¸°í˜¸ë¥¼ ê³µë°±ìœ¼ë¡œ ë³€í™˜ (ì˜ˆ: "ìµœì¸í¬&ì˜¤í˜œì£¼" -> "ìµœì¸í¬ ì˜¤í˜œì£¼")
    text = text.replace("&", " ")
    # ì—¬ëŸ¬ ê³µë°±ì„ í•˜ë‚˜ë¡œ ë³€í™˜
    text = " ".join(text.split())
    
    return text.strip()


def _remove_all_special_chars(text: str) -> str:
    """
    í…ìŠ¤íŠ¸ì—ì„œ ëª¨ë“  íŠ¹ìˆ˜ê¸°í˜¸ë¥¼ ì œê±°í•˜ê³  í•œê¸€, ì˜ë¬¸ì, ìˆ«ì, ê³µë°±ë§Œ ë‚¨ê¸´ë‹¤.
    ê²€ìƒ‰ ì‹¤íŒ¨ ì‹œ ì¬ì‹œë„ë¥¼ ìœ„í•´ ì‚¬ìš©ëœë‹¤.
    
    Args:
        text: ì²˜ë¦¬í•  í…ìŠ¤íŠ¸
    
    Returns:
        íŠ¹ìˆ˜ê¸°í˜¸ê°€ ì œê±°ëœ í…ìŠ¤íŠ¸
    """
    if not text:
        return ""
    
    import re
    # í•œê¸€(ê°€-í£), ì˜ë¬¸ì(a-z, A-Z), ìˆ«ì(0-9), ê³µë°±ë§Œ ë‚¨ê¸°ê³  ë‚˜ë¨¸ì§€ ëª¨ë‘ ì œê±°
    text = re.sub(r'[^a-zA-Z0-9\sê°€-í£]', '', text)
    # ì—¬ëŸ¬ ê³µë°±ì„ í•˜ë‚˜ë¡œ ë³€í™˜
    text = " ".join(text.split())
    
    return text.strip()


def _build_search_query(song_name: str, artist_name: str, album_name: str) -> str:
    """
    ê³¡ëª…, ì•„í‹°ìŠ¤íŠ¸ëª…, ì•¨ë²”ëª…ì„ í•©ì³ GENIE ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ìƒì„±í•œë‹¤.

    Args:
        song_name: ê³¡ëª…
        artist_name: ì•„í‹°ìŠ¤íŠ¸ëª…
        album_name: ì•¨ë²”ëª…

    Returns:
        ê²€ìƒ‰ ì¿¼ë¦¬ ë¬¸ìì—´
    """
    # íŠ¹ìˆ˜ë¬¸ì ì •ì œ
    song_name = _sanitize_search_text(song_name)
    artist_name = _sanitize_search_text(artist_name)
    album_name = _sanitize_search_text(album_name)

    # GENIEëŠ” "ê³¡ëª…/ì•„í‹°ìŠ¤íŠ¸ëª…" í˜•ì‹ì„ ì„ í˜¸í•˜ì§€ë§Œ, ì•¨ë²”ëª… í¬í•¨ ì‹œ ê³µë°± ì‚¬ìš©
    # ì•¨ë²”ëª…ì´ ìˆìœ¼ë©´ ëª¨ë‘ ê³µë°±ìœ¼ë¡œ ê²°í•©
    if album_name:
        parts = []
        if song_name:
            parts.append(song_name)
        if artist_name:
            parts.append(artist_name)
        if album_name:
            parts.append(album_name)
        return " ".join(parts) if parts else ""
    # ê³¡ëª…ê³¼ ì•„í‹°ìŠ¤íŠ¸ëª…ë§Œ ìˆëŠ” ê²½ìš° "/" ì‚¬ìš©
    elif song_name and artist_name:
        return f"{song_name}/{artist_name}"
    # ê³¡ëª…ë§Œ ìˆê±°ë‚˜ ì•„í‹°ìŠ¤íŠ¸ëª…ë§Œ ìˆëŠ” ê²½ìš°
    elif song_name:
        return song_name
    elif artist_name:
        return artist_name
    else:
        return ""


def _build_search_url(query: str) -> str:
    """
    GENIE ê²€ìƒ‰ URLì„ ìƒì„±í•œë‹¤.

    í•œê¸€/ê³µë°± ë“±ì´ í¬í•¨ëœ ê²€ìƒ‰ì–´ë¥¼ ì•ˆì „í•˜ê²Œ GET ì¿¼ë¦¬ìŠ¤íŠ¸ë§ìœ¼ë¡œ ì¸ì½”ë”©í•˜ê¸° ìœ„í•´
    urllib.parse.urlencodeë¥¼ ì‚¬ìš©í•œë‹¤.
    """
    import urllib.parse

    base = "https://www.genie.co.kr/search/searchSong"
    qs = urllib.parse.urlencode({"query": query})
    return f"{base}?{qs}"


def _extract_song_id(html: str) -> Optional[str]:
    """GENIE ê²€ìƒ‰ ê²°ê³¼ HTMLì—ì„œ ì²« ë²ˆì§¸ ê³¡ì˜ song_idë¥¼ ì¶”ì¶œí•œë‹¤."""
    soup = BeautifulSoup(html, "html.parser")
    # ì¼ë°˜ì ìœ¼ë¡œ ê³¡ ë¦¬ìŠ¤íŠ¸ì—ì„œ detail/songInfo?xgnm=XXXX í˜•íƒœì˜ ë§í¬ë¥¼ ì‚¬ìš©
    for a in soup.find_all("a"):
        onclick = a.get("onclick") or ""
        if "fnViewSongInfo" in onclick:
            import re

            m = re.search(r"fnViewSongInfo\('(\d+)'\)", onclick)
            if m:
                return m.group(1)
    return None


def _write_song_ids_csv(platform: str, song_data_list: List[Dict[str, str]], resource_dir: str) -> List[Dict[str, str]]:
    """
    song_data.csv íŒŒì¼ì„ ìƒˆë¡œìš´ ëª…ì„¸ì— ë§ì¶° 17ê°œ ì»¬ëŸ¼ìœ¼ë¡œ ì €ì¥í•œë‹¤.
    
    Returns:
        ì¤‘ë³µ ì œê±°ëœ ê³¡ë“¤ì˜ ì •ë³´ ë¦¬ìŠ¤íŠ¸
    """
    import json
    
    csv_path = Path(resource_dir) / platform / "song_data.csv"
    csv_path.parent.mkdir(parents=True, exist_ok=True)

    # ì¤‘ë³µ ì œê±° (track_cd ê¸°ì¤€)
    unique_data = []
    seen_track_codes = {}  # track_cd -> ì²« ë²ˆì§¸ ë°ì´í„° ë§¤í•‘
    duplicates = []  # ì¤‘ë³µëœ ê³¡ ëª©ë¡
    
    for data in song_data_list:
        track_cd = data.get("track_cd", "").strip()
        if track_cd:
            if track_cd not in seen_track_codes:
                seen_track_codes[track_cd] = data
                unique_data.append(data)
            else:
                # ì¤‘ë³µ ë°œê²¬
                first_data = seen_track_codes[track_cd]
                duplicates.append({
                    "track_cd": track_cd,
                    "first_song_id": first_data.get("platform_song_id", ""),
                    "duplicate_song_id": data.get("platform_song_id", ""),
                    "song_name": data.get("song_name_kor", ""),
                    "artist_name": data.get("artist_name_kor", "")
                })

    # ìƒˆë¡œìš´ ì»¬ëŸ¼ ìˆœì„œ (ëª…ì„¸ì— ë§ì¶¤ - 20ê°œ í•„ë“œ)
    fieldnames = [
        "platform_seq",
        "platform_name",
        "song_type_txt",
        "album_cd",
        "album_name_kor",
        "album_name_eng",
        "song_cd",
        "song_name_kor",
        "song_name_eng",
        "song_release_date",
        "artist_cd",
        "artist_name_kor",
        "artist_name_eng",
        "mem_cd",
        "mem_name",
        "track_cd",
        "isrc_cd",
        "interest_yn",
        "platform_artist_ids",
        "platform_song_ids"
    ]

    with open(csv_path, "w", encoding="utf-8", newline="") as f:
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        writer.writeheader()
        
        for data in unique_data:
            # platform_song_idsë¥¼ JSON ë¬¸ìì—´ë¡œ ë³€í™˜
            platform_song_id = data.get("platform_song_id", "")
            platform_song_ids_json = json.dumps({platform.upper(): platform_song_id}) if platform_song_id else "{}"
            
            # platform_artist_idsëŠ” í˜„ì¬ ë¯¸ìˆ˜ì§‘ì´ë¯€ë¡œ ë¹ˆ ë¬¸ìì—´
            platform_artist_ids_json = ""
            
            writer.writerow({
                "platform_seq": data.get("platform_seq", ""),
                "platform_name": data.get("platform_name", ""),
                "song_type_txt": data.get("song_type_txt", ""),
                "album_cd": data.get("album_cd", ""),
                "album_name_kor": data.get("album_name_kor", ""),
                "album_name_eng": data.get("album_name_eng", ""),
                "song_cd": data.get("song_cd", ""),
                "song_name_kor": data.get("song_name_kor", ""),
                "song_name_eng": data.get("song_name_eng", ""),
                "song_release_date": data.get("song_release_date", ""),
                "artist_cd": data.get("artist_cd", ""),
                "artist_name_kor": data.get("artist_name_kor", ""),
                "artist_name_eng": data.get("artist_name_eng", ""),
                "mem_cd": data.get("mem_cd", ""),
                "mem_name": data.get("mem_name", ""),
                "track_cd": data.get("track_cd", ""),
                "isrc_cd": data.get("isrc_cd", ""),
                "interest_yn": data.get("interest_yn", "n"),
                "platform_artist_ids": platform_artist_ids_json,
                "platform_song_ids": platform_song_ids_json
            })

    logger.info(f"[{platform}] song_data.csvì— {len(unique_data)}ê°œì˜ ê³¡ ì •ë³´ë¥¼ ê¸°ë¡í–ˆìŠµë‹ˆë‹¤: {csv_path}")
    return duplicates


def generate_song_ids(config_path: str) -> None:
    """configì™€ search_data.csvë¥¼ ê¸°ë°˜ìœ¼ë¡œ song_data.csvë¥¼ ìƒì„±/ê°±ì‹ í•œë‹¤."""
    config = load_config(config_path)
    resource_dir = config.get("resource_dir", "resource")
    platforms_config = config.get("platforms", {})

    # enabled_platformsì— í¬í•¨ëœ í”Œë«í¼ë§Œ ì²˜ë¦¬
    enabled_platforms = set(config.get("enabled_platforms", []))

    fetcher = Fetcher(mode="requests", timeout_sec=config.get("http", {}).get("timeout_sec", 20))

    try:
        for platform_name in platforms_config.keys():
            platform = platform_name.upper()
            if platform not in enabled_platforms:
                logger.info(f"[{platform}] enabled_platformsì— í¬í•¨ë˜ì§€ ì•Šì•„ ê±´ë„ˆëœë‹ˆë‹¤.")
                continue

            rows = _read_search_data(platform, resource_dir)
            if not rows:
                continue

            song_data_list: List[Dict[str, str]] = []
            failed_songs: List[Dict[str, str]] = []  # ì‹¤íŒ¨í•œ ê³¡ ëª©ë¡
            for row in rows:
                # ê²€ìƒ‰ìš© í•„ë“œ
                song_name = row.get("song_name", "")
                artist_name = row.get("artist_name", "")
                album_name = row.get("album_name", "")
                
                song_id = None
                tried_queries = []
                
                # ë‹¤ë‹¨ê³„ ê²€ìƒ‰ ì‹œë„
                # 1ë‹¨ê³„: ì›ë³¸ ê·¸ëŒ€ë¡œ ê²€ìƒ‰
                query1 = _build_search_query(song_name, artist_name, album_name)
                if query1:
                    tried_queries.append(query1)
                    try:
                        search_url = _build_search_url(query1)
                        logger.info(f"[GENIE] [1ë‹¨ê³„] ê²€ìƒ‰: '{query1}'")
                        html = fetcher.fetch_html(search_url)
                        song_id = _extract_song_id(html)
                        if song_id:
                            logger.info(f"[GENIE] âœ… [1ë‹¨ê³„] ì„±ê³µ - song_id={song_id}")
                    except Exception as e:
                        logger.error(f"[GENIE] [1ë‹¨ê³„] ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")

                # 2ë‹¨ê³„: ì•¨ë²”ëª…/ì•„í‹°ìŠ¤íŠ¸ëª… ì „ì²˜ë¦¬ í›„ ê²€ìƒ‰
                if not song_id:
                    preprocessed_album = _preprocess_album_name(album_name)
                    preprocessed_artist = _preprocess_artist_name(artist_name)
                    query2 = _build_search_query(song_name, preprocessed_artist, preprocessed_album)

                    if query2 and query2 not in tried_queries:
                        tried_queries.append(query2)
                        try:
                            search_url = _build_search_url(query2)
                            logger.info(f"[GENIE] [2ë‹¨ê³„] ì „ì²˜ë¦¬ ê²€ìƒ‰: '{query2}'")
                            html = fetcher.fetch_html(search_url)
                            song_id = _extract_song_id(html)
                            if song_id:
                                logger.info(f"[GENIE] âœ… [2ë‹¨ê³„] ì„±ê³µ - song_id={song_id}")
                        except Exception as e:
                            logger.error(f"[GENIE] [2ë‹¨ê³„] ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")

                # 3ë‹¨ê³„: ì•¨ë²”ëª… ì—†ì´ ê²€ìƒ‰ (ê³¡ëª… + ì „ì²˜ë¦¬ëœ ì•„í‹°ìŠ¤íŠ¸ëª…)
                if not song_id:
                    preprocessed_artist = _preprocess_artist_name(artist_name)
                    query3 = _build_search_query(song_name, preprocessed_artist, "")

                    if query3 and query3 not in tried_queries:
                        tried_queries.append(query3)
                        try:
                            search_url = _build_search_url(query3)
                            logger.info(f"[GENIE] [3ë‹¨ê³„] ì•¨ë²”ëª… ì œì™¸ ê²€ìƒ‰: '{query3}'")
                            html = fetcher.fetch_html(search_url)
                            song_id = _extract_song_id(html)
                            if song_id:
                                logger.info(f"[GENIE] âœ… [3ë‹¨ê³„] ì„±ê³µ - song_id={song_id}")
                        except Exception as e:
                            logger.error(f"[GENIE] [3ë‹¨ê³„] ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
                
                # 4ë‹¨ê³„: íŠ¹ìˆ˜ê¸°í˜¸ ì œê±° í›„ ê²€ìƒ‰
                if not song_id:
                    song_name_cleaned = _remove_all_special_chars(song_name)
                    artist_name_cleaned = _remove_all_special_chars(artist_name)
                    query4 = _build_search_query(song_name_cleaned, artist_name_cleaned, "")

                    if query4 and query4 not in tried_queries:
                        tried_queries.append(query4)
                        try:
                            search_url = _build_search_url(query4)
                            logger.info(f"[GENIE] [4ë‹¨ê³„] íŠ¹ìˆ˜ê¸°í˜¸ ì œê±° ê²€ìƒ‰: '{query4}'")
                            html = fetcher.fetch_html(search_url)
                            song_id = _extract_song_id(html)
                            if song_id:
                                logger.info(f"[GENIE] âœ… [4ë‹¨ê³„] ì„±ê³µ - song_id={song_id}")
                        except Exception as e:
                            logger.error(f"[GENIE] [4ë‹¨ê³„] ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")

                # 5ë‹¨ê³„: ê³¡ëª…/ì•„í‹°ìŠ¤íŠ¸ëª… ê´„í˜¸ ì œê±° (aggressive)
                if not song_id:
                    song_name_aggressive = _preprocess_song_name(song_name, aggressive=True)
                    artist_name_aggressive = _preprocess_artist_name(artist_name, aggressive=True)
                    query5 = _build_search_query(song_name_aggressive, artist_name_aggressive, "")

                    if query5 and query5 not in tried_queries:
                        tried_queries.append(query5)
                        try:
                            search_url = _build_search_url(query5)
                            logger.info(f"[GENIE] [5ë‹¨ê³„] ê´„í˜¸ ì œê±° ê²€ìƒ‰: '{query5}'")
                            html = fetcher.fetch_html(search_url)
                            song_id = _extract_song_id(html)
                            if song_id:
                                logger.info(f"[GENIE] âœ… [5ë‹¨ê³„] ì„±ê³µ - song_id={song_id}")
                        except Exception as e:
                            logger.error(f"[GENIE] [5ë‹¨ê³„] ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")

                # 6ë‹¨ê³„: ê³¡ëª…ë§Œìœ¼ë¡œ ê²€ìƒ‰ (ì•„í‹°ìŠ¤íŠ¸ ì œì™¸)
                if not song_id:
                    song_name_aggressive = _preprocess_song_name(song_name, aggressive=True)
                    query6 = _build_search_query(song_name_aggressive, "", "")

                    if query6 and query6 not in tried_queries:
                        tried_queries.append(query6)
                        try:
                            search_url = _build_search_url(query6)
                            logger.info(f"[GENIE] [6ë‹¨ê³„] ê³¡ëª…ë§Œ ê²€ìƒ‰: '{query6}'")
                            html = fetcher.fetch_html(search_url)
                            song_id = _extract_song_id(html)
                            if song_id:
                                logger.info(f"[GENIE] âœ… [6ë‹¨ê³„] ì„±ê³µ - song_id={song_id}")
                        except Exception as e:
                            logger.error(f"[GENIE] [6ë‹¨ê³„] ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")

                # 7ë‹¨ê³„: íŠ¹ìˆ˜ê¸°í˜¸ ì œê±° + ê³¡ëª…ë§Œ
                if not song_id:
                    song_name_cleaned = _remove_all_special_chars(song_name)
                    query7 = _build_search_query(song_name_cleaned, "", "")

                    if query7 and query7 not in tried_queries:
                        tried_queries.append(query7)
                        try:
                            search_url = _build_search_url(query7)
                            logger.info(f"[GENIE] [7ë‹¨ê³„] íŠ¹ìˆ˜ê¸°í˜¸ ì œê±° + ê³¡ëª…ë§Œ: '{query7}'")
                            html = fetcher.fetch_html(search_url)
                            song_id = _extract_song_id(html)
                            if song_id:
                                logger.info(f"[GENIE] âœ… [7ë‹¨ê³„] ì„±ê³µ - song_id={song_id}")
                            else:
                                logger.warning(f"[GENIE] âŒ ëª¨ë“  ë‹¨ê³„ ì‹¤íŒ¨ (7ë‹¨ê³„ê¹Œì§€): {song_name} - {artist_name}")
                        except Exception as e:
                            logger.error(f"[GENIE] [7ë‹¨ê³„] ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
                
                # song_idë¥¼ ì°¾ì€ ê²½ìš°ì—ë§Œ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
                if song_id:
                    # ëª¨ë“  í•„ë“œë¥¼ í¬í•¨í•˜ì—¬ ì¶”ê°€ (ìƒˆë¡œìš´ ëª…ì„¸ 20ê°œ í•„ë“œ)
                    song_data_list.append({
                        "platform_song_id": song_id,  # í”Œë«í¼ë³„ song_id
                        "platform_seq": row.get("platform_seq", ""),
                        "platform_name": row.get("platform_name", ""),
                        "song_type_txt": row.get("song_type_txt", ""),
                        "album_cd": row.get("album_cd", ""),
                        "album_name_kor": row.get("album_name_kor", ""),
                        "album_name_eng": row.get("album_name_eng", ""),
                        "song_cd": row.get("song_cd", ""),
                        "song_name_kor": row.get("song_name_kor", ""),
                        "song_name_eng": row.get("song_name_eng", ""),
                        "song_release_date": row.get("song_release_date", ""),
                        "artist_cd": row.get("artist_cd", ""),
                        "artist_name_kor": row.get("artist_name_kor", ""),
                        "artist_name_eng": row.get("artist_name_eng", ""),
                        "mem_cd": row.get("mem_cd", ""),
                        "mem_name": row.get("mem_name", ""),
                        "track_cd": row.get("track_cd", ""),
                        "isrc_cd": row.get("isrc_cd", ""),
                        "interest_yn": row.get("interest_yn", "n"),
                    })
                else:
                    # ì‹¤íŒ¨í•œ ê³¡ ì •ë³´ ì €ì¥
                    failed_songs.append({
                        "song_name": song_name,
                        "artist_name": artist_name,
                        "album_name": album_name,
                        "track_cd": row.get("track_cd", ""),
                        "isrc_cd": row.get("isrc_cd", ""),
                        "song_type_text": row.get("song_type_text", "")
                    })

            # ê²°ê³¼ ì €ì¥
            duplicates = []
            if song_data_list:
                duplicates = _write_song_ids_csv(platform, song_data_list, resource_dir)
            else:
                logger.warning(f"[{platform}] ê²€ìƒ‰ ê²°ê³¼ì—ì„œ song_idë¥¼ ì „í˜€ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            
            # í†µê³„ ì¶œë ¥
            total_count = len(rows)
            success_count = len(song_data_list)
            failed_count = len(failed_songs)
            duplicate_count = len(duplicates)
            
            logger.info(f"\n{'='*80}")
            logger.info(f"[{platform}] ê²€ìƒ‰ ì™„ë£Œ - ì´ {total_count}ê³¡ ì¤‘ {success_count}ê³¡ ì„±ê³µ, {failed_count}ê³¡ ì‹¤íŒ¨")
            if duplicate_count > 0:
                logger.info(f"[{platform}] ì¤‘ë³µ ì œê±°: {duplicate_count}ê³¡ (ë™ì¼í•œ track_cd)")
            logger.info(f"{'='*80}")
            
            # ì‹¤íŒ¨í•œ ê³¡ ëª©ë¡ ì¶œë ¥
            if failed_songs:
                logger.warning(f"\n[{platform}] âŒ ê²€ìƒ‰ ì‹¤íŒ¨í•œ ê³¡ ëª©ë¡ ({failed_count}ê³¡):")
                logger.warning(f"{'-'*80}")
                for idx, failed in enumerate(failed_songs, 1):
                    logger.warning(
                        f"{idx}. [{failed['track_cd']}] "
                        f"{failed['song_name']} - {failed['artist_name']} "
                        f"(ì•¨ë²”: {failed['album_name'][:30]}{'...' if len(failed['album_name']) > 30 else ''})"
                    )
                logger.warning(f"{'-'*80}\n")
            
            # ì¤‘ë³µëœ ê³¡ ëª©ë¡ ì¶œë ¥
            if duplicates:
                logger.warning(f"\n[{platform}] ğŸ”„ ì¤‘ë³µ ì œê±°ëœ ê³¡ ëª©ë¡ ({duplicate_count}ê³¡):")
                logger.warning(f"{'-'*80}")
                for idx, dup in enumerate(duplicates, 1):
                    logger.warning(
                        f"{idx}. [track_cd={dup['track_cd']}] "
                        f"{dup['song_name']} - {dup['artist_name']}"
                    )
                    logger.warning(
                        f"   ì²« ë²ˆì§¸: song_id={dup['first_song_id']}, "
                        f"ì¤‘ë³µ: song_id={dup['duplicate_song_id']}"
                    )
                logger.warning(f"{'-'*80}\n")
    finally:
        fetcher.close()


def main():
    """ê²€ìƒ‰ìš© CSVë¥¼ ê¸°ë°˜ìœ¼ë¡œ song_data.csvë¥¼ ìƒì„±í•˜ëŠ” CLI."""
    parser = argparse.ArgumentParser(description="search_data.csvë¥¼ ê¸°ë°˜ìœ¼ë¡œ song_id ìë™ ìƒì„±")
    parser.add_argument(
        "--config",
        default="config.yaml",
        help="ì„¤ì • íŒŒì¼ ê²½ë¡œ (ê¸°ë³¸ê°’: config.yaml)",
    )

    args = parser.parse_args()
    config_path = args.config

    if not Path(config_path).exists():
        logger.error(f"ì„¤ì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {config_path}")
        sys.exit(1)

    generate_song_ids(config_path)


if __name__ == "__main__":
    main()


